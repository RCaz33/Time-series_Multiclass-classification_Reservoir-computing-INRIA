{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# load data\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# test models\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import cross_validate, cross_val_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "import time\n",
    "# feature importance plot\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "another idea was to calculate features of the time series\n",
    "* number of change of signs for each feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linearize(u):\n",
    "    \"\"\"\n",
    "    Fonction pour mettre en 1 seule lignes le tableau de statistiques pd.describe()\n",
    "    \"\"\"\n",
    "    all=[]\n",
    "    for line in range(len(u)):\n",
    "        all.append(u.iloc[line])\n",
    "    return pd.concat(all, axis=0).T\n",
    "\n",
    "def double_integrate(df, col):\n",
    "    df.sort_values(by='t', inplace=True)\n",
    "    velocities = df[col].cumsum()\n",
    "    positions = velocities.cumsum()\n",
    "    return positions\n",
    "\n",
    "\n",
    "def load_data(directory='data/config1', drop_col='', drop_feat='', position=False, puissances=False, change_sign=False,n_segments=1):\n",
    "    all_data=[]\n",
    "    for filename in sorted(os.listdir(directory)):\n",
    "        # lecture fichier\n",
    "        f = os.path.join(directory, filename)\n",
    "        data = pd.read_csv(f)\n",
    "        # ajout des positions\n",
    "        if position:\n",
    "            data['pos_x'] = double_integrate(data,'raw_acceleration_x')\n",
    "            data['pos_y'] = double_integrate(data,'raw_acceleration_y')\n",
    "            data['pos_z'] = double_integrate(data,'raw_acceleration_z')\n",
    "        # ajout des puissances\n",
    "        if puissances:\n",
    "            data['rotation_cubic_x'] = data['rotation_speed_x']**3\n",
    "            data['rotation_cubic_y'] = data['rotation_speed_y']**3\n",
    "            data['rotation_cubic_z'] = data['rotation_speed_z']**3\n",
    "        # feature selection / engineering \n",
    "        if drop_col:\n",
    "            data.drop(columns=drop_col, inplace=True)\n",
    "        u = data.describe().T\n",
    "        if drop_feat:\n",
    "            u.drop(columns=drop_feat, inplace=True)\n",
    "        number = pd.DataFrame(linearize(u)).T\n",
    "        # time segments\n",
    "        if n_segments >1:\n",
    "            n = len(data)//n_segments   # nbe de points par quartiers\n",
    "            quartiles_ =[]\n",
    "            for i in range(n_segments):\n",
    "                quart_ = data[i*n:(i+1)*n]#.drop(columns='t')\n",
    "                int_ = quart_.describe().T\n",
    "                if drop_feat:\n",
    "                    int_.drop(columns=drop_feat, inplace=True)\n",
    "                number = pd.concat([number,pd.DataFrame(linearize(int_)).T],axis=1)\n",
    "        # changement de signes\n",
    "        if change_sign:\n",
    "            for feature in data.columns[1:-1]:  # on ne prend pas le temps ni le label\n",
    "                col_name = 'sign_change_' + feature\n",
    "                data[col_name] = data[feature].apply(lambda x: 1 if x >= 0 else -1)\n",
    "                number[col_name] = (data[col_name] * data[col_name].shift(-1) < 0).sum()\n",
    "        # get correct label\n",
    "        if directory == 'data/h_config1-lcb':\n",
    "            number['label'] = filename[2]\n",
    "        elif directory == 'data/v_config1-lcb':\n",
    "            number['label'] = int(filename[10])\n",
    "        elif directory == 'data/groupe1 - groupe2':\n",
    "            number['groupe'] = filename[1]\n",
    "            number['label'] = int(filename.split('_')[1])\n",
    "        else :\n",
    "            number['label'] = int(filename[0])\n",
    "        # concatenate\n",
    "        all_data.append(number)   \n",
    "    return pd.concat(all_data)#, _.columns, u.columns\n",
    "\n",
    "def test_models(to_test='to_test'):\n",
    "    \"\"\"\n",
    "    Fonction permettant de tester 4 modèles pour la classification avec 10 split de cross-validation\n",
    "    to_test : pd.DataFrame()\n",
    "    \"\"\"\n",
    "\n",
    "    sc = StandardScaler()\n",
    "    X=sc.fit_transform(to_test.drop(\"label\", axis=1))\n",
    "    y=to_test[\"label\"].astype(int)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
    "    sss = StratifiedShuffleSplit(n_splits=10, test_size=0.3, random_state=42)\n",
    "    models=[\n",
    "        LogisticRegression(solver='liblinear'),\n",
    "        DecisionTreeClassifier(),\n",
    "        RandomForestClassifier()\n",
    "    ]\n",
    "\n",
    "    for model in models:\n",
    "        cv =cross_validate(model,X_train,y_train,cv=10)\n",
    "        print(f\"{model} score :{round(cv['test_score'].mean(),2)}, time {round(cv['score_time'].mean(),4)}\")\n",
    "    return X, y, X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## On a 3 jeux de données déssinés differemments ; \n",
    "* horizontal (sur une tabe ), \n",
    "* vertical (sur un mur), \n",
    "* 3D (dans l'espace)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aquisition 'v'(vertical) en 2D contre un mur (1 groupe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--> Dataset Groupe5:\n",
      "LogisticRegression(solver='liblinear') score :0.93, time 0.0004\n",
      "DecisionTreeClassifier() score :0.6, time 0.0003\n",
      "RandomForestClassifier() score :0.93, time 0.0037\n"
     ]
    }
   ],
   "source": [
    "print (\"\\n--> Dataset Groupe5:\")\n",
    "to_test4 = load_data('data/v_config1-lcb',drop_col='t')\n",
    "X, y, X_train, X_test, y_train, y_test = test_models(to_test4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aquisition 'h' (horizontal) en 2D sur une table (2 groupes)\n",
    "Le nombre de changement de signes de chacune des variables peut être calculé pour chacun des datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--> Dataset Groupe3:\n",
      "LogisticRegression(solver='liblinear') score :0.87, time 0.0003\n",
      "DecisionTreeClassifier() score :0.76, time 0.0002\n",
      "RandomForestClassifier() score :0.96, time 0.0037\n",
      "\n",
      "--> Dataset Groupe4:\n",
      "LogisticRegression(solver='liblinear') score :0.88, time 0.0003\n",
      "DecisionTreeClassifier() score :0.74, time 0.0003\n",
      "RandomForestClassifier() score :0.94, time 0.0038\n",
      "\n",
      "--> Dataset combinés\n",
      "LogisticRegression(solver='liblinear') score :0.76, time 0.0003\n",
      "DecisionTreeClassifier() score :0.66, time 0.0003\n",
      "RandomForestClassifier() score :0.92, time 0.004\n"
     ]
    }
   ],
   "source": [
    "print (\"\\n--> Dataset Groupe3:\")\n",
    "to_test = load_data('data/group3/config_1',drop_col='t')\n",
    "X, y, X_train, X_test, y_train, y_test = test_models(to_test)\n",
    "to_test['groupe'] = '1'\n",
    "print (\"\\n--> Dataset Groupe4:\")\n",
    "to_test2 = load_data('data/h_config1-lcb', drop_col='t')\n",
    "X, y, X_train, X_test, y_train, y_test = test_models(to_test2)\n",
    "to_test2['groupe'] = '2'\n",
    "print (\"\\n--> Dataset combinés\")\n",
    "to_test3 = pd.concat([to_test,to_test2], axis=0)\n",
    "X, y, X_train, X_test, y_train, y_test = test_models(to_test3.drop(columns='groupe'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aquisition 'libre' en 3D dans toutes les directions (2 groupes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--> Dataset Groupe1:\n",
      "LogisticRegression(solver='liblinear') score :0.79, time 0.0003\n",
      "DecisionTreeClassifier() score :0.51, time 0.0002\n",
      "RandomForestClassifier() score :0.82, time 0.0037\n",
      "\n",
      "--> Dataset Groupe2:\n",
      "LogisticRegression(solver='liblinear') score :0.81, time 0.0002\n",
      "DecisionTreeClassifier() score :0.53, time 0.0002\n",
      "RandomForestClassifier() score :0.78, time 0.0036\n",
      "\n",
      "--> Dataset Groupe 1-2:\n",
      "LogisticRegression(solver='liblinear') score :0.56, time 0.0003\n",
      "DecisionTreeClassifier() score :0.37, time 0.0003\n",
      "RandomForestClassifier() score :0.74, time 0.0036\n"
     ]
    }
   ],
   "source": [
    "print (\"\\n--> Dataset Groupe1:\")\n",
    "to_test5 = load_data('data/groupe1 - groupe2',drop_col='t')\n",
    "X, y, X_train, X_test, y_train, y_test = test_models(to_test5.loc[to_test5.groupe == '1'].drop(columns=['groupe']))\n",
    "print (\"\\n--> Dataset Groupe2:\")\n",
    "to_test5 = load_data('data/groupe1 - groupe2',drop_col='t')\n",
    "X, y, X_train, X_test, y_train, y_test = test_models(to_test5.loc[to_test5.groupe == '2'].drop(columns=['groupe']))\n",
    "print (\"\\n--> Dataset Groupe 1-2:\")\n",
    "to_test5 = load_data('data/groupe1 - groupe2',drop_col='t')\n",
    "X, y, X_train, X_test, y_train, y_test = test_models(to_test5.drop(columns=['groupe']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* les score de datset de groupes pris individuellement sont toujours meilleurs que les les scores de datasest combinés"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyses des features "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### On peut regarder l'effet de chaque feature statistique (count,mean,std,...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " --> using only ** count **\n",
      "LogisticRegression(solver='liblinear') score :0.14, time 0.0002\n",
      "DecisionTreeClassifier() score :0.16, time 0.0002\n",
      "RandomForestClassifier() score :0.14, time 0.0036\n",
      "\n",
      " --> using only ** mean **\n",
      "LogisticRegression(solver='liblinear') score :0.63, time 0.0002\n",
      "DecisionTreeClassifier() score :0.56, time 0.0002\n",
      "RandomForestClassifier() score :0.77, time 0.0035\n",
      "\n",
      " --> using only ** std **\n",
      "LogisticRegression(solver='liblinear') score :0.63, time 0.0002\n",
      "DecisionTreeClassifier() score :0.55, time 0.0002\n",
      "RandomForestClassifier() score :0.76, time 0.0036\n",
      "\n",
      " --> using only ** min **\n",
      "LogisticRegression(solver='liblinear') score :0.57, time 0.0002\n",
      "DecisionTreeClassifier() score :0.6, time 0.0002\n",
      "RandomForestClassifier() score :0.7, time 0.0036\n",
      "\n",
      " --> using only ** 25% **\n",
      "LogisticRegression(solver='liblinear') score :0.57, time 0.0002\n",
      "DecisionTreeClassifier() score :0.52, time 0.0002\n",
      "RandomForestClassifier() score :0.75, time 0.0036\n",
      "\n",
      " --> using only ** 50% **\n",
      "LogisticRegression(solver='liblinear') score :0.46, time 0.0002\n",
      "DecisionTreeClassifier() score :0.44, time 0.0002\n",
      "RandomForestClassifier() score :0.66, time 0.0036\n",
      "\n",
      " --> using only ** 75% **\n",
      "LogisticRegression(solver='liblinear') score :0.52, time 0.0002\n",
      "DecisionTreeClassifier() score :0.51, time 0.0002\n",
      "RandomForestClassifier() score :0.76, time 0.0035\n",
      "\n",
      " --> using only ** max **\n",
      "LogisticRegression(solver='liblinear') score :0.62, time 0.0002\n",
      "DecisionTreeClassifier() score :0.56, time 0.0002\n",
      "RandomForestClassifier() score :0.77, time 0.0035\n"
     ]
    }
   ],
   "source": [
    "stats__ = to_test3.describe().index.tolist()\n",
    "for _ in range(len(stats__)):\n",
    "    stats_ = stats__.copy()\n",
    "    removed_element = stats_[_]\n",
    "    print(f\"\\n --> using only ** {removed_element} **\")\n",
    "    stats_.remove(removed_element)\n",
    "    to_test5 = load_data('data/v_config1-lcb', drop_col='t',drop_feat=stats_)\n",
    "    X, y, X_train, X_test, y_train, y_test = test_models(to_test5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* les predictions sont les meilleures lorsqu'on utilise le mean de chaque variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### On peut ajouter des feautures supplémentaires et utiliser leurs 'means' (position / puissance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "juste les means \n",
      "LogisticRegression(solver='liblinear') score :0.63, time 0.0002\n",
      "DecisionTreeClassifier() score :0.57, time 0.0002\n",
      "RandomForestClassifier() score :0.8, time 0.0035\n",
      "\n",
      "means + position\n",
      "LogisticRegression(solver='liblinear') score :0.74, time 0.0002\n",
      "DecisionTreeClassifier() score :0.6, time 0.0002\n",
      "RandomForestClassifier() score :0.85, time 0.0035\n",
      "\n",
      "means + puissances\n",
      "LogisticRegression(solver='liblinear') score :0.66, time 0.0003\n",
      "DecisionTreeClassifier() score :0.6, time 0.0002\n",
      "RandomForestClassifier() score :0.81, time 0.0036\n",
      "\n",
      "means + chgmt sign + position + puissance\n",
      "LogisticRegression(solver='liblinear') score :0.72, time 0.0002\n",
      "DecisionTreeClassifier() score :0.68, time 0.0002\n",
      "RandomForestClassifier() score :0.85, time 0.0035\n"
     ]
    }
   ],
   "source": [
    "stats__ = to_test3.describe().index.tolist()\n",
    "stats__.remove('mean')\n",
    "\n",
    "print(\"\\njuste les means \")\n",
    "to_test5 = load_data('data/v_config1-lcb', drop_col=['t'],drop_feat=stats__)\n",
    "X, y, X_train, X_test, y_train, y_test = test_models(to_test5)\n",
    "\n",
    "print(\"\\nmeans + position\")\n",
    "to_test5 = load_data('data/v_config1-lcb', drop_col=['t'],drop_feat=stats__, position=True)\n",
    "X, y, X_train, X_test, y_train, y_test = test_models(to_test5)\n",
    "\n",
    "print(\"\\nmeans + puissances\")\n",
    "to_test5 = load_data('data/v_config1-lcb', drop_col=['t'],drop_feat=stats__, puissances=True)\n",
    "X, y, X_train, X_test, y_train, y_test = test_models(to_test5)\n",
    "\n",
    "print(\"\\nmeans + chgmt sign + position + puissance\")\n",
    "to_test5 = load_data('data/v_config1-lcb', drop_col=['t'],drop_feat=stats__, position=True, puissances=True)\n",
    "X, y, X_train, X_test, y_train, y_test = test_models(to_test5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* utiliser le mean des position (integration discrete des accelerations) permet d'augmenter les scores de precision\n",
    "### on peut aussi ajouter des features comme le nombre de changement de signes de chacune des variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "means + chgmt sign\n",
      "LogisticRegression(solver='liblinear') score :0.68, time 0.0002\n",
      "DecisionTreeClassifier() score :0.55, time 0.0002\n",
      "RandomForestClassifier() score :0.84, time 0.0035\n",
      "\n",
      "means + chgmt sign + position\n",
      "LogisticRegression(solver='liblinear') score :0.78, time 0.0002\n",
      "DecisionTreeClassifier() score :0.66, time 0.0002\n",
      "RandomForestClassifier() score :0.84, time 0.0036\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"\\nmeans + chgmt sign\")\n",
    "to_test5 = load_data('data/v_config1-lcb', drop_col=['t'],drop_feat=stats__, change_sign=True)\n",
    "X, y, X_train, X_test, y_train, y_test = test_models(to_test5)\n",
    "\n",
    "print(\"\\nmeans + chgmt sign + position\")\n",
    "to_test5 = load_data('data/v_config1-lcb', drop_col=['t'],drop_feat=stats__, position=True, change_sign=True)\n",
    "X, y, X_train, X_test, y_train, y_test = test_models(to_test5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* l'ajout de la feauture changement de signe permet d'augmente encore la precision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### On test alors l'effet de l'ajout de ces features en utilisant toutes les statistiques (count, mean, std, ...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "means \n",
      "LogisticRegression(solver='liblinear') score :0.93, time 0.0002\n",
      "DecisionTreeClassifier() score :0.66, time 0.0002\n",
      "RandomForestClassifier() score :0.92, time 0.0036\n",
      "\n",
      "means + chgmt sign + position \n",
      "LogisticRegression(solver='liblinear') score :0.95, time 0.0002\n",
      "DecisionTreeClassifier() score :0.62, time 0.0002\n",
      "RandomForestClassifier() score :0.95, time 0.0036\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nmeans \")\n",
    "to_test5 = load_data('data/v_config1-lcb', drop_col=['t'])\n",
    "X, y, X_train, X_test, y_train, y_test = test_models(to_test5)\n",
    "\n",
    "print(\"\\nmeans + chgmt sign + position \")\n",
    "to_test5 = load_data('data/v_config1-lcb', drop_col=['t'], position=True, change_sign=True)\n",
    "X, y, X_train, X_test, y_train, y_test = test_models(to_test5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* L'ajout de ces nouvelles features (chgmt sign et position) combiné à toutes les statistiques augment drastiquement les scores de la regr logistique et du random forest classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### on teste sur les autres datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--> Dataset 3D avec position et chgmt signe:\n",
      "LogisticRegression(solver='liblinear') score :0.63, time 0.0003\n",
      "DecisionTreeClassifier() score :0.47, time 0.0003\n",
      "RandomForestClassifier() score :0.75, time 0.0036\n",
      "\n",
      "--> Dataset horizontal avec position et chgmt signe:\n",
      "LogisticRegression(solver='liblinear') score :0.79, time 0.0002\n",
      "DecisionTreeClassifier() score :0.65, time 0.0003\n",
      "RandomForestClassifier() score :0.92, time 0.0037\n"
     ]
    }
   ],
   "source": [
    "print (\"\\n--> Dataset 3D avec position et chgmt signe:\")\n",
    "to_test4 = load_data('data/groupe1 - groupe2',drop_col='t', position=True, change_sign=True)\n",
    "X, y, X_train, X_test, y_train, y_test = test_models(to_test4.drop(columns=['groupe']))\n",
    "\n",
    "print (\"\\n--> Dataset horizontal avec position et chgmt signe:\")\n",
    "to_test = load_data('data/group3/config_1',drop_col='t', position=True, change_sign=True)\n",
    "to_test2 = load_data('data/h_config1-lcb', drop_col='t', position=True, change_sign=True)\n",
    "to_test3 = pd.concat([to_test,to_test2], axis=0)\n",
    "X, y, X_train, X_test, y_train, y_test = test_models(to_test3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --> Dataset Groupe 1-2 (3D)\n",
    "# LinearRegression() score :0.06, time 0.0002\n",
    "# LogisticRegression(solver='liblinear') score :0.56, time 0.0004\n",
    "# DecisionTreeClassifier() score :0.44, time 0.0003\n",
    "# RandomForestClassifier() score :0.73, time 0.0039\n",
    "\n",
    "# --> Dataset combinés (horizontal)\n",
    "# LinearRegression() score :-0.05, time 0.0002\n",
    "# LogisticRegression(solver='liblinear') score :0.76, time 0.0003\n",
    "# DecisionTreeClassifier() score :0.67, time 0.0004\n",
    "# RandomForestClassifier() score :0.93, time 0.0042"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalement, nous pouvons decouper la série temporelle en un nombre n de segments afin d'en extraire les statistiques comme precedemmend\n",
    "# Stratification temporelle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1 segment de temps\n",
      "LogisticRegression(solver='liblinear') score :0.48, time 0.0002\n",
      "DecisionTreeClassifier() score :0.56, time 0.0002\n",
      "RandomForestClassifier() score :0.77, time 0.0036\n",
      "\n",
      "2 segment de temps\n",
      "LogisticRegression(solver='liblinear') score :0.7, time 0.0002\n",
      "DecisionTreeClassifier() score :0.78, time 0.0002\n",
      "RandomForestClassifier() score :0.88, time 0.0035\n",
      "\n",
      "3 segment de temps\n",
      "LogisticRegression(solver='liblinear') score :0.87, time 0.0002\n",
      "DecisionTreeClassifier() score :0.8, time 0.0002\n",
      "RandomForestClassifier() score :0.94, time 0.0036\n",
      "\n",
      "4 segment de temps\n",
      "LogisticRegression(solver='liblinear') score :0.84, time 0.0002\n",
      "DecisionTreeClassifier() score :0.8, time 0.0002\n",
      "RandomForestClassifier() score :0.93, time 0.0035\n",
      "\n",
      "8 segment de temps\n",
      "LogisticRegression(solver='liblinear') score :0.83, time 0.0002\n",
      "DecisionTreeClassifier() score :0.75, time 0.0002\n",
      "RandomForestClassifier() score :0.93, time 0.0035\n"
     ]
    }
   ],
   "source": [
    "feat2drop=['count', 'std', 'min', '25%', '50%', '75%', 'max']\n",
    "\n",
    "print(\"\\n1 segment de temps\")\n",
    "to_test_time1 = load_data(directory='data/h_config1-lcb', drop_col='t', drop_feat=feat2drop, position=False, puissances=False, change_sign=False,n_segments=1)\n",
    "X, y, X_train, X_test, y_train, y_test = test_models(to_test_time1)\n",
    "print(\"\\n2 segment de temps\")\n",
    "to_test_time2 = load_data(directory='data/h_config1-lcb', drop_col='t', drop_feat=feat2drop, position=False, puissances=False, change_sign=False,n_segments=2)\n",
    "X, y, X_train, X_test, y_train, y_test = test_models(to_test_time2)\n",
    "print(\"\\n3 segment de temps\")\n",
    "to_test_time3 = load_data(directory='data/h_config1-lcb', drop_col='t', drop_feat=feat2drop, position=False, puissances=False, change_sign=False,n_segments=3)\n",
    "X, y, X_train, X_test, y_train, y_test = test_models(to_test_time3)\n",
    "print(\"\\n4 segment de temps\")\n",
    "to_test_time4 = load_data(directory='data/h_config1-lcb', drop_col='t', drop_feat=feat2drop, position=False, puissances=False, change_sign=False,n_segments=4)\n",
    "X, y, X_train, X_test, y_train, y_test = test_models(to_test_time4)\n",
    "print(\"\\n8 segment de temps\")\n",
    "to_test_time8 = load_data(directory='data/h_config1-lcb', drop_col='t', drop_feat=feat2drop, position=False, puissances=False, change_sign=False,n_segments=8)\n",
    "X, y, X_train, X_test, y_train, y_test = test_models(to_test_time8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* On atteind un maximum de precision avec 3 segments de temps\n",
    "# toutes les features engineered + 3 segments de temps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "3 segment de temps et toputes les meilleur features\n",
      "LogisticRegression(solver='liblinear') score :0.95, time 0.0004\n",
      "DecisionTreeClassifier() score :0.8, time 0.0003\n",
      "RandomForestClassifier() score :0.96, time 0.0036\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n3 segment de temps et toputes les meilleur features\")\n",
    "to_test_final = load_data(directory='data/h_config1-lcb', drop_col='t', drop_feat='', position=True, puissances=False, change_sign=True,n_segments=3)\n",
    "X, y, X_train, X_test, y_train, y_test = test_models(to_test_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--> Dataset 3D avec position et chgmt signe:\n",
      "LogisticRegression(solver='liblinear') score :0.74, time 0.0004\n",
      "DecisionTreeClassifier() score :0.38, time 0.0003\n",
      "RandomForestClassifier() score :0.73, time 0.0036\n",
      "\n",
      "--> Dataset horizontal avec position et chgmt signe:\n",
      "LogisticRegression(solver='liblinear') score :0.89, time 0.0006\n",
      "DecisionTreeClassifier() score :0.69, time 0.0003\n",
      "RandomForestClassifier() score :0.94, time 0.0039\n"
     ]
    }
   ],
   "source": [
    "print (\"\\n--> Dataset 3D avec position et chgmt signe:\")\n",
    "to_test4 = load_data('data/groupe1 - groupe2', drop_col='t', drop_feat='', position=True, puissances=False, change_sign=True,n_segments=3)\n",
    "X, y, X_train, X_test, y_train, y_test = test_models(to_test4.drop(columns=['groupe']))\n",
    "\n",
    "print (\"\\n--> Dataset horizontal avec position et chgmt signe:\")\n",
    "to_test = load_data('data/group3/config_1', drop_col='t', drop_feat='', position=True, puissances=False, change_sign=True,n_segments=3)\n",
    "to_test2 = load_data('data/h_config1-lcb', drop_col='t', drop_feat='', position=True, puissances=False, change_sign=True,n_segments=3)\n",
    "to_test3 = pd.concat([to_test,to_test2], axis=0)\n",
    "X, y, X_train, X_test, y_train, y_test = test_models(to_test3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
