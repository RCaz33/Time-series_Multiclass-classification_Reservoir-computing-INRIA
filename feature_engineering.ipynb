{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# load data\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# test models\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import cross_validate, cross_val_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "import time\n",
    "# feature importance plot\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "another idea was to calculate features of the time series\n",
    "* number of change of signs for each feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linearize(u):\n",
    "    \"\"\"\n",
    "    Fonction pour mettre en 1 seule lignes le tableau de statistiques pd.describe()\n",
    "    \"\"\"\n",
    "    all=[]\n",
    "    for line in range(len(u)):\n",
    "        all.append(u.iloc[line])\n",
    "    return pd.concat(all, axis=0).T\n",
    "\n",
    "def double_integrate(df, col):\n",
    "    df.sort_values(by='t', inplace=True)\n",
    "    velocities = df[col].cumsum()\n",
    "    positions = velocities.cumsum()\n",
    "    return positions\n",
    "\n",
    "\n",
    "def load_data(directory='data/config1', drop_col='', drop_feat='', position=False, puissances=False, change_sign=False,n_segments=1):\n",
    "    all_data=[]\n",
    "    for filename in sorted(os.listdir(directory)):\n",
    "        # lecture fichier\n",
    "        f = os.path.join(directory, filename)\n",
    "        data = pd.read_csv(f)\n",
    "        # ajout des positions\n",
    "        if position:\n",
    "            data['pos_x'] = double_integrate(data,'raw_acceleration_x')\n",
    "            data['pos_y'] = double_integrate(data,'raw_acceleration_y')\n",
    "            data['pos_z'] = double_integrate(data,'raw_acceleration_z')\n",
    "        # ajout des puissances\n",
    "        if puissances:\n",
    "            data['rotation_cubic_x'] = data['rotation_speed_x']**3\n",
    "            data['rotation_cubic_y'] = data['rotation_speed_y']**3\n",
    "            data['rotation_cubic_z'] = data['rotation_speed_z']**3\n",
    "        # feature selection / engineering \n",
    "        if drop_col:\n",
    "            data.drop(columns=drop_col, inplace=True)\n",
    "        u = data.describe().T\n",
    "        if drop_feat:\n",
    "            u.drop(columns=drop_feat, inplace=True)\n",
    "        number = pd.DataFrame(linearize(u)).T\n",
    "        # time segments\n",
    "        if n_segments >1:\n",
    "            n = len(data)//n_segments   # nbe de points par quartiers\n",
    "            quartiles_ =[]\n",
    "            for i in range(n_segments):\n",
    "                quart_ = data[i*n:(i+1)*n]#.drop(columns='t')\n",
    "                int_ = quart_.describe().T\n",
    "                if drop_feat:\n",
    "                    int_.drop(columns=drop_feat, inplace=True)\n",
    "                number = pd.concat([number,pd.DataFrame(linearize(int_)).T],axis=1)\n",
    "        # changement de signes\n",
    "        if change_sign:\n",
    "            for feature in data.columns[1:-1]:  # on ne prend pas le temps ni le label\n",
    "                col_name = 'sign_change_' + feature\n",
    "                data[col_name] = data[feature].apply(lambda x: 1 if x >= 0 else -1)\n",
    "                number[col_name] = (data[col_name] * data[col_name].shift(-1) < 0).sum()\n",
    "        # get correct label\n",
    "        if directory == 'data/h_config1-lcb':\n",
    "            number['label'] = filename[2]\n",
    "        elif directory == 'data/v_config1-lcb':\n",
    "            number['label'] = int(filename[10])\n",
    "        elif directory == 'data/groupe1_groupe2':\n",
    "            number['groupe'] = filename[1]\n",
    "            number['label'] = int(filename.split('_')[1])\n",
    "        else :\n",
    "            number['label'] = int(filename[0])\n",
    "        # concatenate\n",
    "        all_data.append(number)   \n",
    "    return pd.concat(all_data)#, _.columns, u.columns\n",
    "\n",
    "def test_models(to_test='to_test'):\n",
    "    \"\"\"\n",
    "    Fonction permettant de tester 4 modèles pour la classification avec 10 split de cross-validation\n",
    "    to_test : pd.DataFrame()\n",
    "    \"\"\"\n",
    "\n",
    "    sc = StandardScaler()\n",
    "    X=sc.fit_transform(to_test.drop(\"label\", axis=1))\n",
    "    y=to_test[\"label\"].astype(int)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
    "    sss = StratifiedShuffleSplit(n_splits=10, test_size=0.3, random_state=42)\n",
    "    models=[\n",
    "        LogisticRegression(solver='liblinear'),\n",
    "        DecisionTreeClassifier(),\n",
    "        RandomForestClassifier()\n",
    "    ]\n",
    "\n",
    "    for model in models:\n",
    "        cv =cross_validate(model,X_train,y_train,cv=10)\n",
    "        print(f\"{model} score :{round(cv['test_score'].mean(),2)}, time {round(cv['score_time'].mean(),4)}\")\n",
    "    return X, y, X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## On a 3 jeux de données déssinés differemments ; \n",
    "* horizontal (sur une tabe ), \n",
    "* vertical (sur un mur), \n",
    "* 3D (dans l'espace)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aquisition 'v'(vertical) en 2D contre un mur (1 groupe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--> Dataset Groupe5:\n",
      "LogisticRegression(solver='liblinear') score :0.93, time 0.0007\n",
      "DecisionTreeClassifier() score :0.6, time 0.0003\n",
      "RandomForestClassifier() score :0.92, time 0.0038\n"
     ]
    }
   ],
   "source": [
    "print (\"\\n--> Dataset Groupe5:\")\n",
    "to_test4 = load_data('data/v_config1-lcb',drop_col='t')\n",
    "X, y, X_train, X_test, y_train, y_test = test_models(to_test4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aquisition 'h' (horizontal) en 2D sur une table (2 groupes)\n",
    "Le nombre de changement de signes de chacune des variables peut être calculé pour chacun des datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--> Dataset Groupe3:\n",
      "LogisticRegression(solver='liblinear') score :0.87, time 0.0003\n",
      "DecisionTreeClassifier() score :0.72, time 0.0003\n",
      "RandomForestClassifier() score :0.95, time 0.0036\n",
      "\n",
      "--> Dataset Groupe4:\n",
      "LogisticRegression(solver='liblinear') score :0.88, time 0.0003\n",
      "DecisionTreeClassifier() score :0.76, time 0.0003\n",
      "RandomForestClassifier() score :0.94, time 0.0041\n",
      "\n",
      "--> Dataset combinés\n",
      "LogisticRegression(solver='liblinear') score :0.76, time 0.0008\n",
      "DecisionTreeClassifier() score :0.68, time 0.0004\n",
      "RandomForestClassifier() score :0.92, time 0.004\n"
     ]
    }
   ],
   "source": [
    "print (\"\\n--> Dataset Groupe3:\")\n",
    "to_test = load_data('data/group3/config_1',drop_col='t')\n",
    "X, y, X_train, X_test, y_train, y_test = test_models(to_test)\n",
    "to_test['groupe'] = '1'\n",
    "print (\"\\n--> Dataset Groupe4:\")\n",
    "to_test2 = load_data('data/h_config1-lcb', drop_col='t')\n",
    "X, y, X_train, X_test, y_train, y_test = test_models(to_test2)\n",
    "to_test2['groupe'] = '2'\n",
    "print (\"\\n--> Dataset combinés\")\n",
    "to_test3 = pd.concat([to_test,to_test2], axis=0)\n",
    "X, y, X_train, X_test, y_train, y_test = test_models(to_test3.drop(columns='groupe'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aquisition 'libre' en 3D dans toutes les directions (2 groupes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--> Dataset Groupe1:\n",
      "LogisticRegression(solver='liblinear') score :0.79, time 0.0002\n",
      "DecisionTreeClassifier() score :0.47, time 0.0003\n",
      "RandomForestClassifier() score :0.84, time 0.0036\n",
      "\n",
      "--> Dataset Groupe2:\n",
      "LogisticRegression(solver='liblinear') score :0.81, time 0.0003\n",
      "DecisionTreeClassifier() score :0.54, time 0.0005\n",
      "RandomForestClassifier() score :0.79, time 0.0039\n",
      "\n",
      "--> Dataset Groupe 1-2:\n",
      "LogisticRegression(solver='liblinear') score :0.56, time 0.0003\n",
      "DecisionTreeClassifier() score :0.42, time 0.0003\n",
      "RandomForestClassifier() score :0.69, time 0.004\n"
     ]
    }
   ],
   "source": [
    "print (\"\\n--> Dataset Groupe1:\")\n",
    "to_test5 = load_data('data/groupe1_groupe2',drop_col='t')\n",
    "X, y, X_train, X_test, y_train, y_test = test_models(to_test5.loc[to_test5.groupe == '1'].drop(columns=['groupe']))\n",
    "print (\"\\n--> Dataset Groupe2:\")\n",
    "to_test5 = load_data('data/groupe1_groupe2',drop_col='t')\n",
    "X, y, X_train, X_test, y_train, y_test = test_models(to_test5.loc[to_test5.groupe == '2'].drop(columns=['groupe']))\n",
    "print (\"\\n--> Dataset Groupe 1-2:\")\n",
    "to_test5 = load_data('data/groupe1_groupe2',drop_col='t')\n",
    "X, y, X_train, X_test, y_train, y_test = test_models(to_test5.drop(columns=['groupe']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* les score de datset de groupes pris individuellement sont toujours meilleurs que les les scores de datasest combinés"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyses des features "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### On peut regarder l'effet de chaque feature statistique (count,mean,std,...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " --> using only ** count **\n",
      "LogisticRegression(solver='liblinear') score :0.14, time 0.0003\n",
      "DecisionTreeClassifier() score :0.16, time 0.0002\n",
      "RandomForestClassifier() score :0.11, time 0.0038\n",
      "\n",
      " --> using only ** mean **\n",
      "LogisticRegression(solver='liblinear') score :0.63, time 0.0002\n",
      "DecisionTreeClassifier() score :0.56, time 0.0002\n",
      "RandomForestClassifier() score :0.81, time 0.0038\n",
      "\n",
      " --> using only ** std **\n",
      "LogisticRegression(solver='liblinear') score :0.63, time 0.0003\n",
      "DecisionTreeClassifier() score :0.55, time 0.0003\n",
      "RandomForestClassifier() score :0.77, time 0.0038\n",
      "\n",
      " --> using only ** min **\n",
      "LogisticRegression(solver='liblinear') score :0.57, time 0.0002\n",
      "DecisionTreeClassifier() score :0.59, time 0.0002\n",
      "RandomForestClassifier() score :0.71, time 0.0039\n",
      "\n",
      " --> using only ** 25% **\n",
      "LogisticRegression(solver='liblinear') score :0.57, time 0.0003\n",
      "DecisionTreeClassifier() score :0.53, time 0.0002\n",
      "RandomForestClassifier() score :0.73, time 0.0039\n",
      "\n",
      " --> using only ** 50% **\n",
      "LogisticRegression(solver='liblinear') score :0.46, time 0.0002\n",
      "DecisionTreeClassifier() score :0.44, time 0.0002\n",
      "RandomForestClassifier() score :0.67, time 0.0039\n",
      "\n",
      " --> using only ** 75% **\n",
      "LogisticRegression(solver='liblinear') score :0.52, time 0.0002\n",
      "DecisionTreeClassifier() score :0.53, time 0.0002\n",
      "RandomForestClassifier() score :0.75, time 0.0037\n",
      "\n",
      " --> using only ** max **\n",
      "LogisticRegression(solver='liblinear') score :0.62, time 0.0002\n",
      "DecisionTreeClassifier() score :0.53, time 0.0002\n",
      "RandomForestClassifier() score :0.75, time 0.0037\n"
     ]
    }
   ],
   "source": [
    "stats__ = to_test3.describe().index.tolist()\n",
    "for _ in range(len(stats__)):\n",
    "    stats_ = stats__.copy()\n",
    "    removed_element = stats_[_]\n",
    "    print(f\"\\n --> using only ** {removed_element} **\")\n",
    "    stats_.remove(removed_element)\n",
    "    to_test5 = load_data('data/v_config1-lcb', drop_col='t',drop_feat=stats_)\n",
    "    X, y, X_train, X_test, y_train, y_test = test_models(to_test5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* la statistique COUNT ne permet pas de bonnes prédictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### On peut ajouter des feautures supplémentaires et utiliser leurs 'means' (position / puissance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "juste les means \n",
      "LogisticRegression(solver='liblinear') score :0.63, time 0.0002\n",
      "DecisionTreeClassifier() score :0.53, time 0.0002\n",
      "RandomForestClassifier() score :0.78, time 0.0037\n",
      "\n",
      "means + position\n",
      "LogisticRegression(solver='liblinear') score :0.74, time 0.0002\n",
      "DecisionTreeClassifier() score :0.61, time 0.0002\n",
      "RandomForestClassifier() score :0.84, time 0.0037\n",
      "\n",
      "means + puissances\n",
      "LogisticRegression(solver='liblinear') score :0.66, time 0.0002\n",
      "DecisionTreeClassifier() score :0.59, time 0.0002\n",
      "RandomForestClassifier() score :0.82, time 0.0038\n",
      "\n",
      "means + chgmt sign + position + puissance\n",
      "LogisticRegression(solver='liblinear') score :0.72, time 0.0002\n",
      "DecisionTreeClassifier() score :0.65, time 0.0003\n",
      "RandomForestClassifier() score :0.84, time 0.0038\n"
     ]
    }
   ],
   "source": [
    "stats__ = to_test3.describe().index.tolist()\n",
    "stats__.remove('mean')\n",
    "\n",
    "print(\"\\njuste les means \")\n",
    "to_test5 = load_data('data/v_config1-lcb', drop_col=['t'],drop_feat=stats__)\n",
    "X, y, X_train, X_test, y_train, y_test = test_models(to_test5)\n",
    "\n",
    "print(\"\\nmeans + position\")\n",
    "to_test5 = load_data('data/v_config1-lcb', drop_col=['t'],drop_feat=stats__, position=True)\n",
    "X, y, X_train, X_test, y_train, y_test = test_models(to_test5)\n",
    "\n",
    "print(\"\\nmeans + puissances\")\n",
    "to_test5 = load_data('data/v_config1-lcb', drop_col=['t'],drop_feat=stats__, puissances=True)\n",
    "X, y, X_train, X_test, y_train, y_test = test_models(to_test5)\n",
    "\n",
    "print(\"\\nmeans + position + puissance\")\n",
    "to_test5 = load_data('data/v_config1-lcb', drop_col=['t'],drop_feat=stats__, position=True, puissances=True)\n",
    "X, y, X_train, X_test, y_train, y_test = test_models(to_test5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Faire du feature engineering permet d'augmenter la precision des predictions \n",
    "* les puissances n'aident pas à améliorer les scores de classification\n",
    "### on peut aussi ajouter des features comme le nombre de changement de signes de chacune des variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "means + chgmt sign\n",
      "LogisticRegression(solver='liblinear') score :0.68, time 0.0002\n",
      "DecisionTreeClassifier() score :0.56, time 0.0002\n",
      "RandomForestClassifier() score :0.82, time 0.0037\n",
      "\n",
      "means + chgmt sign + position\n",
      "LogisticRegression(solver='liblinear') score :0.78, time 0.0004\n",
      "DecisionTreeClassifier() score :0.65, time 0.0002\n",
      "RandomForestClassifier() score :0.84, time 0.0037\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"\\nmeans + chgmt sign\")\n",
    "to_test5 = load_data('data/v_config1-lcb', drop_col=['t'],drop_feat=stats__, change_sign=True)\n",
    "X, y, X_train, X_test, y_train, y_test = test_models(to_test5)\n",
    "\n",
    "print(\"\\nmeans + chgmt sign + position\")\n",
    "to_test5 = load_data('data/v_config1-lcb', drop_col=['t'],drop_feat=stats__, position=True, change_sign=True)\n",
    "X, y, X_train, X_test, y_train, y_test = test_models(to_test5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* l'ajout de la feauture changement de signe permet d'augmente encore la precision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### On teste alors l'effet de l'ajout de ces features en utilisant toutes les statistiques (count, mean, std, ...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sans les variables supplémentaires (toutes les statistiques)\n",
      "LogisticRegression(solver='liblinear') score :0.94, time 0.0003\n",
      "DecisionTreeClassifier() score :0.64, time 0.0002\n",
      "RandomForestClassifier() score :0.91, time 0.0037\n",
      "\n",
      "Avec chgmt sign + position (toutes les statistiques)\n",
      "LogisticRegression(solver='liblinear') score :0.95, time 0.0003\n",
      "DecisionTreeClassifier() score :0.64, time 0.0003\n",
      "RandomForestClassifier() score :0.94, time 0.0038\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nSans les variables supplémentaires (toutes les statistiques sauf count)\")\n",
    "to_test5 = load_data('data/v_config1-lcb', drop_col=['t'], drop_feat='count')\n",
    "X, y, X_train, X_test, y_train, y_test = test_models(to_test5)\n",
    "\n",
    "print(\"\\nAvec chgmt sign + position (toutes les statistiques)\")\n",
    "to_test5 = load_data('data/v_config1-lcb', drop_col=['t'], drop_feat='count', position=True, change_sign=True)\n",
    "X, y, X_train, X_test, y_train, y_test = test_models(to_test5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* L'ajout de ces nouvelles features (chgmt sign et position) combiné à toutes les statistiques augment drastiquement les scores de la regr logistique et du random forest classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### on teste sur les autres datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--> Dataset 3D avec position et chgmt signe:\n",
      "LogisticRegression(solver='liblinear') score :0.63, time 0.0003\n",
      "DecisionTreeClassifier() score :0.42, time 0.0003\n",
      "RandomForestClassifier() score :0.74, time 0.0038\n",
      "\n",
      "--> Dataset horizontal avec position et chgmt signe:\n",
      "LogisticRegression(solver='liblinear') score :0.79, time 0.0003\n",
      "DecisionTreeClassifier() score :0.64, time 0.0003\n",
      "RandomForestClassifier() score :0.93, time 0.0039\n"
     ]
    }
   ],
   "source": [
    "print (\"\\n--> Dataset 3D avec position et chgmt signe:\")\n",
    "to_test4 = load_data('data/groupe1_groupe2',drop_col='t', drop_feat='count', position=True, change_sign=True)\n",
    "X, y, X_train, X_test, y_train, y_test = test_models(to_test4.drop(columns=['groupe']))\n",
    "\n",
    "print (\"\\n--> Dataset horizontal avec position et chgmt signe:\")\n",
    "to_test = load_data('data/group3/config_1',drop_col='t', drop_feat='count', position=True, change_sign=True)\n",
    "to_test2 = load_data('data/h_config1-lcb', drop_col='t', drop_feat='count', position=True, change_sign=True)\n",
    "to_test3 = pd.concat([to_test,to_test2], axis=0)\n",
    "X, y, X_train, X_test, y_train, y_test = test_models(to_test3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --> Dataset Groupe 1-2 (3D)\n",
    "# LinearRegression() score :0.06, time 0.0002\n",
    "# LogisticRegression(solver='liblinear') score :0.56, time 0.0004\n",
    "# DecisionTreeClassifier() score :0.44, time 0.0003\n",
    "# RandomForestClassifier() score :0.73, time 0.0039\n",
    "\n",
    "# --> Dataset combinés (horizontal)\n",
    "# LinearRegression() score :-0.05, time 0.0002\n",
    "# LogisticRegression(solver='liblinear') score :0.76, time 0.0003\n",
    "# DecisionTreeClassifier() score :0.67, time 0.0004\n",
    "# RandomForestClassifier() score :0.93, time 0.0042"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalement, nous pouvons decouper la série temporelle en un nombre n de segments afin d'en extraire les statistiques comme precedemmend\n",
    "# Stratification temporelle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1 segment de temps\n",
      "LogisticRegression(solver='liblinear') score :0.48, time 0.0002\n",
      "DecisionTreeClassifier() score :0.58, time 0.0002\n",
      "RandomForestClassifier() score :0.76, time 0.0039\n",
      "\n",
      "2 segment de temps\n",
      "LogisticRegression(solver='liblinear') score :0.7, time 0.0003\n",
      "DecisionTreeClassifier() score :0.76, time 0.0003\n",
      "RandomForestClassifier() score :0.86, time 0.0038\n",
      "\n",
      "3 segment de temps\n",
      "LogisticRegression(solver='liblinear') score :0.87, time 0.0003\n",
      "DecisionTreeClassifier() score :0.78, time 0.0003\n",
      "RandomForestClassifier() score :0.96, time 0.0039\n",
      "\n",
      "4 segment de temps\n",
      "LogisticRegression(solver='liblinear') score :0.84, time 0.0002\n",
      "DecisionTreeClassifier() score :0.84, time 0.0002\n",
      "RandomForestClassifier() score :0.93, time 0.0036\n",
      "\n",
      "8 segment de temps\n",
      "LogisticRegression(solver='liblinear') score :0.83, time 0.0003\n",
      "DecisionTreeClassifier() score :0.76, time 0.0002\n",
      "RandomForestClassifier() score :0.93, time 0.0036\n"
     ]
    }
   ],
   "source": [
    "feat2drop=['count', 'std', 'min', '25%', '50%', '75%', 'max']\n",
    "\n",
    "print(\"\\n1 segment de temps\")\n",
    "to_test_time1 = load_data(directory='data/h_config1-lcb', drop_col='t', drop_feat=feat2drop, position=False, puissances=False, change_sign=False,n_segments=1)\n",
    "X, y, X_train, X_test, y_train, y_test = test_models(to_test_time1)\n",
    "print(\"\\n2 segment de temps\")\n",
    "to_test_time2 = load_data(directory='data/h_config1-lcb', drop_col='t', drop_feat=feat2drop, position=False, puissances=False, change_sign=False,n_segments=2)\n",
    "X, y, X_train, X_test, y_train, y_test = test_models(to_test_time2)\n",
    "print(\"\\n3 segment de temps\")\n",
    "to_test_time3 = load_data(directory='data/h_config1-lcb', drop_col='t', drop_feat=feat2drop, position=False, puissances=False, change_sign=False,n_segments=3)\n",
    "X, y, X_train, X_test, y_train, y_test = test_models(to_test_time3)\n",
    "print(\"\\n4 segment de temps\")\n",
    "to_test_time4 = load_data(directory='data/h_config1-lcb', drop_col='t', drop_feat=feat2drop, position=False, puissances=False, change_sign=False,n_segments=4)\n",
    "X, y, X_train, X_test, y_train, y_test = test_models(to_test_time4)\n",
    "print(\"\\n8 segment de temps\")\n",
    "to_test_time8 = load_data(directory='data/h_config1-lcb', drop_col='t', drop_feat=feat2drop, position=False, puissances=False, change_sign=False,n_segments=8)\n",
    "X, y, X_train, X_test, y_train, y_test = test_models(to_test_time8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* On atteind un maximum de precision avec 3 segments de temps\n",
    "# Toutes les stats descriptives + 2 features engineered + 3 segments de temps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "3 segment de temps et toutes les meilleur features (1 dataset vertical)\n",
      "LogisticRegression(solver='liblinear') score :0.97, time 0.0014\n",
      "DecisionTreeClassifier() score :0.71, time 0.0003\n",
      "RandomForestClassifier() score :0.95, time 0.0036\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n3 segment de temps et toutes les meilleur features (1 dataset vertical)\")\n",
    "to_test_final = load_data(directory='data/v_config1-lcb', drop_col='t', drop_feat='count', position=True, puissances=False, change_sign=True,n_segments=3)\n",
    "X, y, X_train, X_test, y_train, y_test = test_models(to_test_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--> Dataset 3D (2 datasets) avec position et chgmt signe:\n",
      "LogisticRegression(solver='liblinear') score :0.73, time 0.0009\n",
      "DecisionTreeClassifier() score :0.36, time 0.0004\n",
      "RandomForestClassifier() score :0.76, time 0.0039\n",
      "\n",
      "--> Dataset horizontal (2 datasets) avec position et chgmt signe:\n",
      "LogisticRegression(solver='liblinear') score :0.89, time 0.001\n",
      "DecisionTreeClassifier() score :0.67, time 0.0004\n",
      "RandomForestClassifier() score :0.93, time 0.004\n"
     ]
    }
   ],
   "source": [
    "print (\"\\n--> Dataset 3D (2 datasets) avec position et chgmt signe:\")\n",
    "to_test4 = load_data('data/groupe1_groupe2', drop_col='t', drop_feat='count', position=True, puissances=False, change_sign=True,n_segments=3)\n",
    "X, y, X_train, X_test, y_train, y_test = test_models(to_test4.drop(columns=['groupe']))\n",
    "\n",
    "print (\"\\n--> Dataset horizontal (2 datasets) avec position et chgmt signe:\")\n",
    "to_test = load_data('data/group3/config_1', drop_col='t', drop_feat='count', position=True, puissances=False, change_sign=True,n_segments=3)\n",
    "to_test2 = load_data('data/h_config1-lcb', drop_col='t', drop_feat='count', position=True, puissances=False, change_sign=True,n_segments=3)\n",
    "to_test3 = pd.concat([to_test,to_test2], axis=0)\n",
    "X, y, X_train, X_test, y_train, y_test = test_models(to_test3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tous les datsets 2D (3 datasets)\n",
      "LogisticRegression(solver='liblinear') score :0.92, time 0.0009\n",
      "DecisionTreeClassifier() score :0.62, time 0.0004\n",
      "RandomForestClassifier() score :0.96, time 0.0044\n"
     ]
    }
   ],
   "source": [
    "print(\"Tous les datsets 2D (3 datasets)\")\n",
    "to_test4 = pd.concat([to_test_final,to_test,to_test2], axis=0)\n",
    "X, y, X_train, X_test, y_train, y_test = test_models(to_test4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
