{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################\n",
    "####     Données 2023       ###\n",
    "###############################\n",
    "\n",
    "################################\n",
    "##   juste MEAN / STD         ##\n",
    "################################\n",
    "\n",
    "\n",
    "import os\n",
    "directory = 'data/v_config1-lcb'#group3/config_1'#/config_3'   # change here to get more data\n",
    "labels=[]\n",
    "all_data=[]\n",
    "for filename in os.listdir(directory):\n",
    "    f = os.path.join(directory, filename)\n",
    "    data = pd.read_csv(f)\n",
    "\n",
    "    u = data.drop(columns=['t']).describe().T[['mean','std']].T\n",
    "    number = pd.DataFrame(pd.concat([u.iloc[0], u.iloc[1]], axis=0)).T\n",
    "    number['label'] = int(filename[10])\n",
    "    number['iteration'] = int(filename.split('_')[3].split('.')[0])\n",
    "\n",
    "    all_data.append(number)\n",
    "\n",
    "to_test = pd.concat(all_data)\n",
    "\n",
    "# merege\n",
    "data1 = pd.read_csv('data/df_nb_sign_changes_v.csv')\n",
    "data1 = data1[['label','iteration','nb_sign_changes_acceleration_x', 'nb_sign_changes_acceleration_y', 'nb_sign_changes_acceleration_z']]\n",
    "\n",
    "data2 = pd.read_csv('data/csv_benoit.csv')\n",
    "data2.rename(columns={\"digit\": \"label\"}, inplace=True)\n",
    "data2 = data2[['label','iteration','changement_acceleration_x',\n",
    "       'changement_acceleration_y', 'changement_acceleration_z',\n",
    "       'changement_rotation_x', 'changement_rotation_y',\n",
    "       'changement_rotation_z', 'changement_magnetisme_x',\n",
    "       'changement_magnetisme_y', 'changement_magnetisme_z']]\n",
    "data2['label'] = data2['label'].astype(int)\n",
    "\n",
    "\n",
    "to_test1 = to_test.merge(data1, on=['label','iteration'], how='inner')\n",
    "to_test3 = to_test1.merge(data2, left_index=True, right_index=True)\n",
    "to_test3.drop(columns=['label_y', 'iteration_y','iteration_x'], inplace=True)\n",
    "to_test3.rename(columns={\"label_x\": \"label\"}, inplace=True)\n",
    "\n",
    "to_test.drop(columns=['iteration'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "\n",
    "def cross_validate_models(model,data,target):\n",
    "    sss = StratifiedShuffleSplit(n_splits=10, test_size=0.3, random_state=42)\n",
    "    cv_results = cross_validate(model, data, target, cv=sss)\n",
    "    cv_results = pd.DataFrame(cv_results)\n",
    "    return cv_results\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************************************\n",
      "DATA du describe\n",
      "Generalization score without hyperparameters tuning:\n",
      "0.655 ± DecisionTreeClassifier() : 0.035\n",
      "Generalization score without hyperparameters tuning:\n",
      "0.786 ± LogisticRegression(max_iter=10000) : 0.031\n",
      "Generalization score without hyperparameters tuning:\n",
      "0.267 ± SVC() : 0.051\n",
      "Generalization score without hyperparameters tuning:\n",
      "0.888 ± RandomForestClassifier() : 0.021\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "models = [DecisionTreeClassifier(), LogisticRegression(max_iter=10000),SVC(), RandomForestClassifier()]  \n",
    "\n",
    "\n",
    "print(50*'*')\n",
    "print('juste \"mean\" et \"sdt\" du describe')\n",
    "for model in models:\n",
    "    cv_results = cross_validate_models(model,to_test.drop(columns='label'), to_test.label)\n",
    "    print(\n",
    "    \"Generalization score without hyperparameters\"\n",
    "    f\" tuning:\\n{cv_results['test_score'].mean():.3f} ±\"\n",
    "    f\" {cv_results['test_score'].std():.3f}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************************************\n",
      "DATA du describe + feature engineering \"nb sign\"\n",
      "Generalization score without hyperparameters tuning:\n",
      "0.642 ± 0.045\n",
      "Generalization score without hyperparameters tuning:\n",
      "0.766 ± 0.034\n",
      "Generalization score without hyperparameters tuning:\n",
      "0.253 ± 0.043\n",
      "Generalization score without hyperparameters tuning:\n",
      "0.893 ± 0.018\n"
     ]
    }
   ],
   "source": [
    "print(50*'*')\n",
    "print('juste \"mean\" et \"sdt\" du describe + feature engineering \"nb sign\"')\n",
    "for model in models:\n",
    "    cv_results = cross_validate_models(model,to_test1.drop(columns='label'), to_test1.label)\n",
    "    print(\n",
    "    \"Generalization score without hyperparameters\"\n",
    "    f\" tuning:\\n{cv_results['test_score'].mean():.3f} ±\"\n",
    "    f\" {cv_results['test_score'].std():.3f}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************************************\n",
      "DATA du describe + feature engineering \"changement\"\n",
      "Generalization score without hyperparameters tuning:\n",
      "0.652 ± 0.041\n",
      "Generalization score without hyperparameters tuning:\n",
      "0.707 ± 0.054\n",
      "Generalization score without hyperparameters tuning:\n",
      "0.243 ± 0.043\n",
      "Generalization score without hyperparameters tuning:\n",
      "0.887 ± 0.036\n"
     ]
    }
   ],
   "source": [
    "print(50*'*')\n",
    "print('juste \"mean\" et \"sdt\" du describe + feature engineering \"nb sign\" & \"changement\"')\n",
    "for model in models:\n",
    "    cv_results = cross_validate_models(model,to_test3.drop(columns='label'), to_test3.label)\n",
    "    print(\n",
    "    \"Generalization score without hyperparameters\"\n",
    "    f\" tuning:\\n{cv_results['test_score'].mean():.3f} ±\"\n",
    "    f\" {cv_results['test_score'].std():.3f}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linearize(u):\n",
    "    all=[]\n",
    "    for line in range(len(u)):\n",
    "        all.append(u.iloc[line])\n",
    "    return pd.concat(all, axis=0).T\n",
    "\n",
    "directory = 'data/v_config1-lcb'\n",
    "labels=[]\n",
    "all_data=[]\n",
    "for filename in os.listdir(directory):\n",
    "    f = os.path.join(directory, filename)\n",
    "    data = pd.read_csv(f)\n",
    "    u = data.drop(columns='t').describe().T.drop(['count'], axis=1)\n",
    "    number = pd.DataFrame(linearize(u)).T\n",
    "    number['label'] = int(filename[10])\n",
    "    number['iteration'] = int(filename.split('_')[3].split('.')[0])\n",
    "\n",
    "    all_data.append(number)\n",
    "    \n",
    "to_test = pd.concat(all_data)\n",
    "\n",
    "# merege\n",
    "data1 = pd.read_csv('data/df_nb_sign_changes_v.csv')\n",
    "data1 = data1[['label','iteration','nb_sign_changes_acceleration_x', 'nb_sign_changes_acceleration_y', 'nb_sign_changes_acceleration_z']]\n",
    "to_test2 = to_test.merge(data1, on=['label','iteration'], how='inner')\n",
    "\n",
    "\n",
    "to_test.drop(columns=['iteration'], inplace=True)\n",
    "to_test2.drop(columns=['iteration'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************************************\n",
      "all DATA du describe\n",
      "Generalization score without hyperparameters tuning:\n",
      "0.685 ± 0.041\n",
      "Generalization score without hyperparameters tuning:\n",
      "0.863 ± 0.021\n",
      "Generalization score without hyperparameters tuning:\n",
      "0.327 ± 0.058\n",
      "Generalization score without hyperparameters tuning:\n",
      "0.926 ± 0.025\n"
     ]
    }
   ],
   "source": [
    "print(50*'*')\n",
    "print('all DATA du describe')\n",
    "for model in models:\n",
    "    cv_results = cross_validate_models(model,to_test.drop(columns='label'), to_test.label)\n",
    "    print(\n",
    "    \"Generalization score without hyperparameters\"\n",
    "    f\" tuning:\\n{cv_results['test_score'].mean():.3f} ±\"\n",
    "    f\" {cv_results['test_score'].std():.3f}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************************************\n",
      "all DATA du describe + \"nb sign\"\n",
      "Generalization score without hyperparameters tuning:\n",
      "0.675 ± 0.046\n",
      "Generalization score without hyperparameters tuning:\n",
      "0.869 ± 0.025\n",
      "Generalization score without hyperparameters tuning:\n",
      "0.325 ± 0.054\n",
      "Generalization score without hyperparameters tuning:\n",
      "0.937 ± 0.015\n"
     ]
    }
   ],
   "source": [
    "print(50*'*')\n",
    "print('all DATA du describe + \"nb sign\"')\n",
    "for model in models:\n",
    "    cv_results = cross_validate_models(model,to_test2.drop(columns='label'), to_test2.label)\n",
    "    print(\n",
    "    \"Generalization score without hyperparameters\"\n",
    "    f\" tuning:\\n{cv_results['test_score'].mean():.3f} ±\"\n",
    "    f\" {cv_results['test_score'].std():.3f}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(to_test.drop(\"label\", axis=1), to_test[\"label\"], test_size=0.3, random_state=42, stratify=to_test[\"label\"])\n",
    "\n",
    "# Créer un modèle d'arbre de décision\n",
    "model = DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
